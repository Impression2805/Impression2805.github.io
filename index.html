<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Fei Zhu</title>
</head>
<body style="width: 1000px; margin: 0 auto;">
<div id="fwtitle">
<div id="toptitle">
<h1>Fei Zhu</h1>
</div>
</div>
<div id="layout-content">
<table class="imgtable"><tr><td>
<img src="zhufei.jpg" alt="photo_me" width="130px" height="180px" />&nbsp;</td>
<td align="left"><p>Postdoctoral Researcher [<a href="https://scholar.google.com/citations?user=fjZ1CBwAAAAJ&hl=zh-CN">Google Scholar</a>] [<a href="https://github.com/Impression2805">Github</a>] <br />
Centre for Artificial Intelligence and Robotics Hong Kong Institute of Science & Innovation <br /> 
Chinese Academy of Sciences</p>
<p>3/F, 17W, Science Park West Avenue, Hong Kong Science Park, Hong Kong.<br />  
Email: zhufei2018 AT ia DOT ac DOT cn</a>

</p>
</td></tr></table>
<h2>About me</h2>
<p>I am currently a postdoctoral fellow at the Centre for Artificial Intelligence and Robotics, Hong Kong Institute of Science & Innovation, Chinese Academy of Sciences. I am fortunate to work with Prof. <a href="https://zhaoxiangzhang.net/">Zhaoxiang Zhang</a>. I received my Ph.D. in Pattern Recognition and Intelligent Systems from
the Institute of Automation, Chinese Academy of Sciences, where I was fortunate to be advised by Prof. <a href="http://www.nlpr.ia.ac.cn/liucl/">Cheng-Lin Liu</a> and Prof. <a href="https://people.ucas.edu.cn/~xuyaozhang">Xu-Yao Zhang</a>. Prior to this, I received the B.E. degree from Tsinghua University.
</p>
<p>
Research Highlights: My research interests include topics in reliability (e.g., confidence estimation, failure detection) and adaptability (e.g., continual learning, novel class discovery) of mechine learning models, especially in the open world/environment applications.  <br />
I am open to discussion or collaboration. Feel free to contact me if you are interested. <br />
</p>

<!--
<h2>News & Updates </h2> 
<ul>

<div style="height:80px;width:fit-content;overflow:auto;background:#FFFFFF;">
	<li>
		<p>[2023/02/28] One paper on <b>misclassification detection</b> is accepted by <b>CVPR</b> 2023, code is coming soon.
			</p>
	</li>
</div>
</ul>
-->

</p>
<h2>Selected Publications </h2>
<ul>
<li><p><i>ContinualFD: Continual Learning for Unified Failure Detection</i>.<br />
<b>Fei Zhu</b>, Zhen Cheng, Xu-Yao Zhang, Cheng-Lin Liu, Zhaoxiang Zhang. <br />  
CVPR 2024 [<a href="">paper</a>] [<a href="">arxiv</a>] [<a href="">code</a>]. <br /></p>
</li>
</ul>
<ul>
<li><p><i>Active Generalized Category Discovery</i>.<br />
Shijie Ma, <b>Fei Zhu</b>, Xu-Yao Zhang, Cheng-Lin Liu. <br />  
CVPR 2024 [<a href="">paper</a>] [<a href="">arxiv</a>] [<a href="">code</a>]. <br /></p>
</li>
</ul>
<ul>
<li><p><i>Revisiting Confidence Estimation: Towards Reliable Failure Prediction</i>.<br />
<b>Fei Zhu</b>, Xu-Yao Zhang, Zhen Cheng, Cheng-Lin Liu. <br />  
TPAMI 2024 [<a href="https://ieeexplore.ieee.org/abstract/document/10356834">paper</a>] [<a href="https://github.com/Impression2805/FMFP">code</a>]. <br /></p>
</li>
</ul>
<ul>
<li><p><i>Learning by Seeing More Classes</i>.<br />
<b>Fei Zhu</b>, Xu-Yao Zhang, Rui-Qi Wang, Cheng-Lin Liu. <br />  
TPAMI 2023 [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9964413">paper</a>]. <br /></p>
</li>
</ul>
<ul>
<li><p><i>Imitating the Oracle: Towards Calibrated Model for Class Incremental Learning</i>.<br />
<b>Fei Zhu</b>, Zhen Cheng, Xu-Yao Zhang, Cheng-Lin Liu. <br />  
Neural Networks 2023 [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608023001879">paper</a>] [<a href="https://github.com/Impression2805/ItO4CIL">code</a>]. <br /></p>
</li>
</ul>
<ul>
<li><p><i>OpenMix: Exploring Outlier Samples for Misclassification Detection</i>.<br />
<b>Fei Zhu</b>, Zhen Cheng, Xu-Yao Zhang, Cheng-Lin Liu. <br />  
CVPR 2023 <font color="red">Highlight Paper</font> (Top 2.5%) [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_OpenMix_Exploring_Outlier_Samples_for_Misclassification_Detection_CVPR_2023_paper.pdf">paper</a>] [<a href="https://arxiv.org/pdf/2303.17093.pdf">arxiv</a>] [<a href="https://github.com/Impression2805/OpenMix">code</a>]. <br /></p>
</li>
</ul>
<ul>
<li><p><i>Rethinking Confidence Calibration for Failure Prediction</i>.<br />
<b>Fei Zhu</b>, Zhen Cheng, Xu-Yao Zhang, Cheng-Lin Liu. <br />  
ECCV 2022 [<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136850512.pdf">paper</a>] [<a href="https://arxiv.org/pdf/2303.02970v1.pdf">arxiv</a>] [<a href="https://github.com/Impression2805/FMFP">code</a>]. <br /></p>
</li>
</ul>
<ul>
<li><p><i>Prototype Augmentation and Self-Supervision for Incremental Learning</i>.<br />
<b>Fei Zhu</b>, Xu-Yao Zhang, Chuang Wang, Fei Yin, Cheng-Lin Liu. <br />  
CVPR 2021 <font color="red">Oral Paper</font> (Top 4%) [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Prototype_Augmentation_and_Self-Supervision_for_Incremental_Learning_CVPR_2021_paper.pdf">paper</a>] [<a href="https://github.com/Impression2805/CVPR21_PASS">code</a>]. <br /></p>
</li>
</ul>
<ul>
<li><p><i>Class-Incremental Learning via Dual Augmentation</i>.<br />
<b>Fei Zhu</b>, Zhen Cheng, Xu-Yao Zhang, Cheng-Lin Liu. <br /> 
NeurIPS 2021 [<a href="https://proceedings.neurips.cc/paper/2021/file/77ee3bc58ce560b86c2b59363281e914-Paper.pdf">paper</a>] [<a href="https://github.com/Impression2805/IL2A">code</a>]. <br /></p>
</li>
</ul>
<ul>
<li><p><i>Class Incremental Learning: A Review and Performance Evaluation (In Chinese)</i>.<br />
<b>Fei Zhu</b>, Xu-Yao Zhang, Cheng-Lin Liu. <br /> 
Acta Automatica Sinica 2023, invited reviews [<a href="http://www.aas.net.cn/cn/article/doi/10.16383/j.aas.c220588?viewType=HTML">paper</a>]. <br /></p>
</li>
</ul>
<ul>
<li><p><i>Adversarial Training with Distribution Normalization and Margin Balance</i>.<br />
Zhen Cheng, <b>Fei Zhu</b>, Xu-Yao Zhang, Cheng-Lin Liu. <br /> 
<b>Pattern Recognition</b> 2023 [<a href="https://www.sciencedirect.com/science/article/pii/S0031320322006616">paper</a>]. <br /></p>
</li>
</ul>
<ul>
<li><p><i>Decoding lip language using triboelectric sensors with deep learning</i>.<br />
Yi-Jia Lu*, Han Tan*, Jia Cheng*, <b>Fei Zhu</b>, Bing Liu, Shan-Shan Wei, LinHong Ji, Zhong-Lin Wang. <br /> 
<b>Nature Communications</b> 2022 <font color="red">Highlight Paper</font> [<a href="https://www.nature.com/articles/s41467-022-29083-0">paper</a>]. <br /></p>
</li>
</ul>

<h2>Preprints </h2> 
<ul>
<li><p><i>Average of Pruning: Improving Performance and Stability of Out-of-Distribution Detection</i>.<br />
Zhen Cheng, <b>Fei Zhu</b>, Xu-Yao Zhang, Cheng-Lin Liu. <br />   
ArXiv 2023 [<a href="https://arxiv.org/pdf/2303.01201.pdf">paper</a>]. <br /></p>
</li>
</ul>

</div>
</body>
</html>
